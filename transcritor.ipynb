{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyAudioAnalysis import ShortTermFeatures as aF\n",
    "from pyAudioAnalysis import audioBasicIO \n",
    "import numpy as np \n",
    "import plotly.graph_objs as go \n",
    "import plotly\n",
    "import IPython\n",
    "from pyAudioAnalysis import audioSegmentation as aS\n",
    "# Load the API\n",
    "from inaSpeechSegmenter import Segmenter\n",
    "from inaSpeechSegmenter.export_funcs import seg2csv, seg2textgrid\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read audio data from file \n",
    "# (returns sampling freq and signal as a numpy array)\n",
    "fs, s = audioBasicIO.read_audio_file(\"18copy.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.display(IPython.display.Audio(\"18copy.wav\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print duration in seconds:\n",
    "duration = len(s) / float(fs)\n",
    "print(f'duration = {duration} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract short-term features using a 50msec non-overlapping windows\n",
    "win, step = 0.070, 0.070\n",
    "[f, fn] = aF.feature_extraction(s, fs, int(fs * win), \n",
    "                                int(fs * step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_media = '18copy.wav'\n",
    "output_media = '18copy_cleaned.wav'\n",
    "output_path = 'audios_extracted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = Segmenter()\n",
    "segmentation = seg(input_media)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg2csv(segmentation, 'myseg.csv')\n",
    "# Here is the resulting CSV\n",
    "# !cat myseg.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('myseg.csv', sep='\\t')\n",
    "df = df[(df['labels'] != 'noEnergy' ) & (df['labels'] != 'noise')]\n",
    "df = df.reset_index(drop=True)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "def cut_audio_from_wav(input_path, file_name, start, end, output_path, output_file):\n",
    "  startSec = start*1000\n",
    "  endSec = end*1000\n",
    "  # Opening file and extracting segment\n",
    "  song = AudioSegment.from_wav(input_path + file_name)\n",
    "  extract = song[startSec:endSec]\n",
    "  # Saving\n",
    "  extract.export(f\"{output_path}/{output_file}\", format=\"wav\")\n",
    "\n",
    "with open('extract_audios.txt', 'w', encoding='utf-8') as  arq:\n",
    "  total_lines = df.shape[0] -1\n",
    "  for index, row in df.iterrows():\n",
    "    try:\n",
    "      \n",
    "      output_file = f\"_18copy_{index}.wav\"\n",
    "      cut_audio_from_wav('', '18copy.wav', row['start'], row['stop'],output_path, output_file)\n",
    "      if index == total_lines:\n",
    "        arq.write(f\"file '{output_path}/{output_file}'\")\n",
    "      else:\n",
    "        arq.write(f\"file '{output_path}/{output_file}'\\n\")\n",
    "    except Exception as e:\n",
    "      print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "txt_full_directory='extract_audios.txt'\n",
    "\n",
    "# cmdargs = \"ffmpeg -f concat -safe 0 -i \" + txt_full_directory + \" -c copy \" + f\"{output_media}\"\n",
    "cmd_args = f\"ffmpeg -f concat -safe 0 -i {txt_full_directory} -c copy {output_media}\"\n",
    "# subprocess.run() will allow the process to end before creating a new one\n",
    "try:\n",
    "  subprocess.run(cmd_args, check=True, shell=True)\n",
    "  print(f\"File {output_media} successfully created\")\n",
    "except Exception as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import sys\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sr.Recognizer()\n",
    "with sr.AudioFile(output_media) as source:\n",
    "   audio_text = r.record(source)\n",
    "   print(audio_text)\n",
    "   text = r.recognize_google(audio_text,language='pt-BR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(f'{output_media}_trancribed.txt', 'w') as arq:\n",
    "  arq.write(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a416688a7d5abe7a158bcaeba049f1ef41b54e75004cd5d3a1b47367f87b7f17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
